{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nxQ05wCU-gb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "print (sys.version)\n",
    "import numpy as np\n",
    "import time\n",
    "import math as mt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qh9pWytkFX7z",
    "outputId": "bfbe26eb-d6f1-41ab-ab14-a0f94dd84438"
   },
   "outputs": [],
   "source": [
    "StartingValuesFromFile=np.load('startingvaluesMultiVariatePoisson.npy')\n",
    "print(StartingValuesFromFile.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In8l4okch-_y"
   },
   "source": [
    "Now calculate the outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sU2tnTWsk4o",
    "outputId": "0e795621-14ea-41b9-850c-221e4909e3c9"
   },
   "outputs": [],
   "source": [
    "YFromFile=np.load('outputsMultiVariatePoisson.npy')\n",
    "print(YFromFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Input, Add\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom activation function\n",
    "vector_z=[1.,1.,1.,1.,1.,1.,1.,1.,1.,1.] #This is the vector z we need to choose in Example 2.12\n",
    "vector_psi=[0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25,0.25] #This is the vector that encodes the function psi in Example 2.12\n",
    "psi=tf.constant(vector_psi)\n",
    "z=tf.constant(vector_z)   \n",
    "\n",
    "def custom_fct(x):\n",
    "    psi_mat=tf.expand_dims(psi, axis=0)\n",
    "    psi_mat_t=tf.transpose(psi_mat)\n",
    "    #psi_mat_batch=tf.broadcast_to(psi_mat, [3,1,3])\n",
    "    tmp=tf.matmul(x,psi_mat_t)\n",
    "    tmp2=K.maximum(tf.zeros_like(tmp),1-K.exp(-tmp))  \n",
    "    tmp3=tmp2*z\n",
    "    return tmp3#tf.math.scalar_mul(tmp4, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6H6DE7FMvRr",
    "outputId": "1d273e70-ce20-417b-da6b-421ef0cf22c4"
   },
   "outputs": [],
   "source": [
    "approxDim=10 #This is the approximation dimension, the number of basis functions we consider\n",
    "\n",
    "def genNetwork2Layer(NbNodesPerLayer):\n",
    "    inputs =  tf.keras.Input(shape=(approxDim,))\n",
    "\n",
    "    nodes1 = [] \n",
    "    nodes2 = []\n",
    "    #After each node is a lambda layer that implements our activation function\n",
    "    lambda_layers1= []\n",
    "    lambda_layers2= []\n",
    "    #Final linear forms that are applied\n",
    "    linear_form_layers=[]\n",
    "    all_linear_form_outputs=[]\n",
    "    for j in range(NbNodesPerLayer):\n",
    "        node1 = Dense(approxDim, activation=None,trainable=True,\n",
    "                    kernel_initializer=initializers.RandomNormal(0,1),#kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',\n",
    "                    name=str('node1_p')+str('_k')+str(k)+str('_j')+str(j))\n",
    "        lamb1= Lambda(custom_fct,name=str('activation_1_p')+str('_k')+str(k)+str('_j')+str(j),output_shape=(approxDim,))\n",
    "        nodes1 = nodes1 + [node1]\n",
    "        \n",
    "        lambda_layers1=lambda_layers1 + [lamb1]\n",
    "        \n",
    "        node2 = Dense(approxDim, activation=None,trainable=True,\n",
    "                    kernel_initializer=initializers.RandomNormal(0,1),#kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',\n",
    "                    name=str('node2_p')+str('_k')+str(k)+str('_j')+str(j))\n",
    "        lamb2= Lambda(custom_fct,name=str('activation_2_p')+str('_k')+str(k)+str('_j')+str(j),output_shape=(approxDim,))\n",
    "        \n",
    "        nodes2 = nodes2 + [node2]\n",
    "        lambda_layers2=lambda_layers2 + [lamb2]\n",
    "        \n",
    "        lin= Dense(1, activation=None,trainable=True,\n",
    "                    kernel_initializer=initializers.RandomNormal(0,1),#kernel_initializer='random_normal',\n",
    "                    use_bias=False,\n",
    "                    name=str('linearForm_p')+str('_k')+str(k)+str('_j')+str(j))\n",
    "\n",
    "        linear_form_layers=linear_form_layers + [lin]\n",
    "\n",
    "        output_linearmap1=nodes1[j](inputs)\n",
    "        output_activation1=lambda_layers1[j](output_linearmap1)\n",
    "        output_linearmap2=nodes2[j](output_activation1)\n",
    "        output_activation2=lambda_layers2[j](output_linearmap2)\n",
    "        output_linear_form=linear_form_layers[j](output_activation2)\n",
    "            \n",
    "        all_linear_form_outputs=all_linear_form_outputs+[output_linear_form]\n",
    "    \n",
    "\n",
    "    #print(all_linear_form_outputs)  \n",
    "        add_layer=Add(name=str('addlayer_p')+str('_k')+str(k))\n",
    "\n",
    "    if NbNodesPerLayer>1:\n",
    "        finalOutput=add_layer(all_linear_form_outputs)\n",
    "        model = Model(inputs=inputs, outputs=finalOutput,name=str('model_p')+str('_k')+str(k))            \n",
    "    else:\n",
    "        model = Model(inputs=inputs, outputs=output_linear_form,name=str('model_p')+str('_k')+str(k))  \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NbDataPartitions=5\n",
    "\n",
    "\n",
    "errors=np.zeros(NbDataPartitions)\n",
    "for k in range(15,20,1):\n",
    "    ticall=time.perf_counter()\n",
    "    for p in range(0,NbDataPartitions,1):\n",
    "    #for p in range(0,1,1):\n",
    "        StartingValues=np.concatenate((StartingValuesFromFile[:p*1000000], StartingValuesFromFile[(p+1)*1000000:]), axis=0)\n",
    "        Y=np.concatenate((YFromFile[:p*1000000], YFromFile[(p+1)*1000000:]), axis=0)\n",
    "        tic = time.perf_counter()\n",
    "        model=genNetwork2Layer(k)\n",
    "        model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "        model.fit(StartingValues, Y, epochs=25, batch_size=10000)\n",
    "        errors[p]=model.evaluate(StartingValuesFromFile[p*1000000:(p+1)*1000000],YFromFile[p*1000000:(p+1)*1000000])\n",
    "        toc = time.perf_counter()\n",
    "        print(f\"Calc time: {(toc - tic)/60.0:0.4f} minutes\")\n",
    "\n",
    "    filename=str('error_model_2Layer')+str(k)\n",
    "    np.save(filename,errors)\n",
    "    tocall=time.perf_counter()\n",
    "    print(f\"Calc time: {(tocall - ticall)/60.0:0.4f} minutes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgerror=np.zeros(19)\n",
    "for k in range(1,20,1):\n",
    "    error=np.load('error_model_2Layer'+str(k)+'.npy')\n",
    "    avgerror[k-1]=np.average(error)\n",
    "\n",
    "print(avgerror)\n",
    "filename=str('avg_error_2layer')\n",
    "np.save(filename,avgerror)\n",
    "\n",
    "bestmodel2Layer=np.argmin(avgerror)\n",
    "\n",
    "avgerror1Layer=np.load('avg_error_1layer.npy')\n",
    "bestmodel1Layer=np.argmin(avgerror1Layer)\n",
    "print(bestmodel1Layer)\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=plt.axes()\n",
    "xvalues=range(1,20,1)\n",
    "#plt.plot(xvalues,avgerror1Layer,avgerror)\n",
    "ax.set(xlabel='number of nodes in hidden layer', ylabel='avg mean squared error',\n",
    "       title='')\n",
    "\n",
    "\n",
    "ax.plot(xvalues,avgerror1Layer,markevery=[bestmodel1Layer], marker=\"o\",label='1-layer')\n",
    "ax.plot(xvalues,avgerror,markevery=[bestmodel2Layer], marker=\"o\",label='2-layer')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=genNetwork2Layer(2)\n",
    "#model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "#StartingValues=np.concatenate((StartingValuesFromFile[:1*1000000], StartingValuesFromFile[(1+1)*1000000:]), axis=0)\n",
    "#Y=np.concatenate((YFromFile[:1*1000000], YFromFile[(1+1)*1000000:]), axis=0)\n",
    "#model.fit(StartingValues, Y, epochs=25, batch_size=10000)\n",
    "#tmperror=model.evaluate(StartingValuesFromFile[1*1000000:(1+1)*1000000],YFromFile[1*1000000:(1+1)*1000000])\n",
    "#error=np.load('error_model_2Layer'+str(2)+'.npy')\n",
    "#print(error)\n",
    "#error[1]=tmperror\n",
    "#filename=str('error_model_2Layer2')\n",
    "#np.save(filename,error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=genNetwork2Layer(bestmodel2Layer)\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(StartingValuesFromFile, YFromFile, epochs=25, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=np.load('startingvaluesMultiVariatePoissonKoefficientTestset100000Sim0.npy')\n",
    "print(tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MCpricesTestset=np.load('outputsMultiVariateTestset.npy')\n",
    "#xvaluesTestset=np.load('startingvaluesMultiVariateTestset.npy')\n",
    "startingValuesTestset=np.zeros([960,10])\n",
    "MCprices=np.zeros([960])\n",
    "for k in range(0,15,1):\n",
    "    tmpstring=\"% s\" % k\n",
    "    filename1=\"startingvaluesMultiVariatePoissonKoefficientTestset100000Sim\"+tmpstring+\".npy\"\n",
    "    filename2=\"outputsMultiVariatePoissonKoefficientTestset100000Sim\"+tmpstring+\".npy\"\n",
    "    tmp1=np.load(filename1)\n",
    "    tmp2=np.load(filename2)\n",
    "    startingValuesTestset[k*64:(k+1)*64]=tmp1\n",
    "    MCprices[k*64:(k+1)*64]=tmp2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mctf=tf.reshape(tf.constant(MCprices),[MCprices.shape[0],1])\n",
    "mctf=tf.dtypes.cast(mctf, tf.float32)\n",
    "mse = tf.keras.losses.MeanSquaredError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train all other networks and calc error\n",
    "mctf=tf.reshape(tf.constant(MCprices),[MCprices.shape[0],1])\n",
    "mctf=tf.dtypes.cast(mctf, tf.float32)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "errorsModels=np.zeros(19)\n",
    "for k in range(1,20,1):\n",
    "    model=genNetwork2Layer(k)\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    model.fit(StartingValuesFromFile, YFromFile, epochs=25, batch_size=10000)\n",
    "    predictions=model(startingValuesTestset)\n",
    "    errorsModels[k-1]=mse(predictions, mctf).numpy()\n",
    "    \n",
    "np.save('error2LayerModels',errorsModels)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error1LayerModels=np.load('error1LayerModels.npy')\n",
    "errorsModels=np.load('error2LayerModels.npy')\n",
    "print(error1LayerModels)\n",
    "\n",
    "best1Layer=np.argmin(error1LayerModels)\n",
    "best2Layer=np.argmin(errorsModels)\n",
    "\n",
    "print(error1LayerModels[best1Layer])\n",
    "\n",
    "print(errorsModels[best2Layer])\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=plt.axes()\n",
    "xvalues=range(1,20,1)\n",
    "#plt.plot(xvalues,avgerror1Layer,avgerror)\n",
    "ax.set(xlabel='number of nodes in hidden layer', ylabel='avg mean squared error',\n",
    "       title='')\n",
    "\n",
    "\n",
    "ax.plot(xvalues,error1LayerModels,markevery=[best1Layer], marker=\"o\",label='1-layer')\n",
    "ax.plot(xvalues,errorsModels,markevery=[best2Layer], marker=\"o\",label='2-layer')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ForwardPricingNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
