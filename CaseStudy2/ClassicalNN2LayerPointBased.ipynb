{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nxQ05wCU-gb"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import math as mt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qh9pWytkFX7z",
    "outputId": "bfbe26eb-d6f1-41ab-ab14-a0f94dd84438"
   },
   "outputs": [],
   "source": [
    "StartingValuesFromFile=np.load('DiscretizedCurve10TrainingsetMultivariatePoisson.npy')\n",
    "print(StartingValuesFromFile.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "In8l4okch-_y"
   },
   "source": [
    "Now calculate the outputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sU2tnTWsk4o",
    "outputId": "0e795621-14ea-41b9-850c-221e4909e3c9"
   },
   "outputs": [],
   "source": [
    "YFromFile=np.load('outputsMultiVariatePoisson.npy')\n",
    "print(YFromFile.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVYXVM2vFVCA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U6H6DE7FMvRr",
    "outputId": "1d273e70-ce20-417b-da6b-421ef0cf22c4"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Lambda\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.layers import Input, Add\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "inputs =  tf.keras.Input(shape=(10,))\n",
    "\n",
    "#nodeHiddenLayer=250\n",
    "\n",
    "#for nodeHiddenLayer in range(5,100,5):\n",
    "def genNetwork(NbNodesPerLayer):\n",
    "\n",
    "    layer = Dense(NbNodesPerLayer, activation='relu',trainable=True,\n",
    "                      kernel_initializer=initializers.RandomNormal(0,1),#kernel_initializer='random_normal',\n",
    "                      bias_initializer='random_normal')\n",
    "    \n",
    "    layer2 = Dense(NbNodesPerLayer, activation='relu',trainable=True,\n",
    "                      kernel_initializer=initializers.RandomNormal(0,1),#kernel_initializer='random_normal',\n",
    "                      bias_initializer='random_normal')\n",
    "\n",
    "    outlayer=Dense(1, activation=None,trainable=True,\n",
    "                      kernel_initializer=initializers.RandomNormal(0,1),#kernel_initializer='random_normal',\n",
    "                      use_bias=False)\n",
    "    \n",
    "    tmp=layer(inputs)\n",
    "    tmp2=layer2(tmp)\n",
    "    finalOutput=outlayer(tmp2)\n",
    "                              \n",
    "    model = Model(inputs=inputs, outputs=finalOutput)\n",
    "\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "NbDataPartitions=5\n",
    "\n",
    "\n",
    "errors=np.zeros(NbDataPartitions)\n",
    "for k in range(10,150,10):\n",
    "    ticall=time.perf_counter()\n",
    "    for p in range(0,NbDataPartitions,1):\n",
    "    #for p in range(0,1,1):\n",
    "        StartingValues=np.concatenate((StartingValuesFromFile[:p*1000000], StartingValuesFromFile[(p+1)*1000000:]), axis=0)\n",
    "        Y=np.concatenate((YFromFile[:p*1000000], YFromFile[(p+1)*1000000:]), axis=0)\n",
    "        tic = time.perf_counter()\n",
    "        model=genNetwork(k)\n",
    "        model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "        model.fit(StartingValues, Y, epochs=25, batch_size=10000)\n",
    "        errors[p]=model.evaluate(StartingValuesFromFile[p*1000000:(p+1)*1000000],YFromFile[p*1000000:(p+1)*1000000])\n",
    "        toc = time.perf_counter()\n",
    "        print(f\"Calc time: {(toc - tic)/60.0:0.4f} minutes\")\n",
    "\n",
    "    filename=str('error_model_classical_2layer')+str(k)\n",
    "    np.save(filename,errors)\n",
    "    tocall=time.perf_counter()\n",
    "print(f\"Calc time: {(tocall - ticall)/60.0:0.4f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgerror1Layer=np.zeros(14)\n",
    "variance1Layer=np.zeros(14)\n",
    "for k in range(1,15,1):\n",
    "    error=np.load('error_model_classical_1layer'+str(k*10)+'.npy')\n",
    "    avgerror1Layer[k-1]=np.average(error)\n",
    "    variance1Layer[k-1]=np.var(error)\n",
    "    print(k)\n",
    "    print(error)\n",
    "\n",
    "\n",
    "avgerror2Layer=np.zeros(14)\n",
    "variance2Layer=np.zeros(14)\n",
    "for k in range(1,15,1):\n",
    "    error=np.load('error_model_classical_2layer'+str(k*10)+'.npy')\n",
    "    avgerror2Layer[k-1]=np.average(error)\n",
    "    variance2Layer[k-1]=np.var(error)\n",
    "    print(k)\n",
    "    print(error)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(variance1Layer)\n",
    "print(variance2Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel1Layer=np.argmin(avgerror1Layer)\n",
    "bestmodel2Layer=np.argmin(avgerror2Layer)\n",
    "xvalues=range(10,150,10)\n",
    "\n",
    "fig=plt.figure()\n",
    "ax=plt.axes()\n",
    "ax.set(xlabel='number of nodes in each hidden nodes', ylabel='avg mean squared error',\n",
    "       title='')\n",
    "ax.plot(xvalues,avgerror1Layer,markevery=[bestmodel1Layer], marker=\"o\",label='1-layer')\n",
    "\n",
    "ax.plot(xvalues,avgerror2Layer,markevery=[bestmodel2Layer], marker=\"o\",label='2-layer')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCpricesTestset=np.load('outputsMultiVariatePoissonTestset100000Simulations.npy')\n",
    "xvaluesTestset=np.load('DiscretizedCurve10TestsetMultivariatePoisson.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrain all with full dataset\n",
    "import time\n",
    "\n",
    "mctf=tf.reshape(tf.constant(MCpricesTestset),[MCpricesTestset.shape[0],1])\n",
    "mctf=tf.dtypes.cast(mctf, tf.float32)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "errorsModels=np.zeros(14)\n",
    "for k in range(1,15,1):\n",
    "    tic = time.perf_counter()\n",
    "    model=genNetwork(k*10)\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "    model.fit(StartingValuesFromFile, YFromFile, epochs=25, batch_size=10000)\n",
    "    predictions=model(xvaluesTestset)\n",
    "    errorsModels[k-1]=mse(predictions, mctf).numpy()\n",
    "    print(errorsModels[k-1])\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Calc time: {(toc - tic)/60.0:0.4f} minutes\")\n",
    "    \n",
    "np.save('msePointBasedMultivariate10discretized2Layer.npy',errorsModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorsModels1Layer=np.load('msePointBasedMultivariate10discretized.npy')\n",
    "print(errorsModels1Layer)\n",
    "\n",
    "errorsModels2Layer=np.load('msePointBasedMultivariate10discretized2Layer.npy')\n",
    "print(errorsModels2Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestmodel1Layer=np.argmin(errorsModels1Layer)\n",
    "bestmodel2Layer=np.argmin(errorsModels2Layer)\n",
    "print(errorsModels1Layer[bestmodel1Layer])\n",
    "print(errorsModels2Layer[bestmodel2Layer])\n",
    "\n",
    "xvalues=range(10,150,10)\n",
    "fig=plt.figure()\n",
    "ax=plt.axes()\n",
    "ax.set(xlabel='number of nodes in hidden nodes', ylabel='mean squared error testset',\n",
    "       title='')\n",
    "ax.plot(xvalues,errorsModels1Layer,markevery=[bestmodel1Layer], marker=\"o\",label='1-layer')\n",
    "ax.plot(xvalues,errorsModels2Layer,markevery=[bestmodel2Layer], marker=\"o\",label='2-layer')\n",
    "#ax.plot(xvalues,avgerror,markevery=[bestmodel2Layer], marker=\"o\",label='2-layer')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylim([0, 0.06])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('msePointBasedMultivariate10discretized',mses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ForwardPricingNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
